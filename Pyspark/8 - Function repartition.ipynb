{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMhJNSHHLtANXK/OJhyJghu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"cellView":"form","id":"wl8PFxdYnGFJ","executionInfo":{"status":"ok","timestamp":1717622569090,"user_tz":300,"elapsed":101404,"user":{"displayName":"Jonatan Alexander Parra Toro","userId":"08257295951347696938"}},"outputId":"f6659da1-2a7d-4215-b7b5-7e30ed3ffc08"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["#@title Instalar Spark\n","# Instalar SDK java 8\n","!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n","\n","# Descargar Spark 3.4.3\n","!wget -q https://archive.apache.org/dist/spark/spark-3.4.3/spark-3.4.3-bin-hadoop3.tgz\n","\n","# Descomprimir el archivo descargado de Spark\n","!tar xf spark-3.4.3-bin-hadoop3.tgz\n","\n","# Establecer las variables de entorno\n","import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = \"/content/spark-3.4.3-bin-hadoop3\"\n","\n","# Instalar la librería findspark\n","!pip install -q findspark\n","\n","# Instalar pyspark\n","!pip install -q pyspark\n"]},{"cell_type":"code","source":["import findspark\n","findspark.init()\n","\n","from pyspark.sql import SparkSession\n","spark = SparkSession.builder.getOrCreate()"],"metadata":{"id":"0ZJA8G_7nWo0","executionInfo":{"status":"ok","timestamp":1717622580270,"user_tz":300,"elapsed":11212,"user":{"displayName":"Jonatan Alexander Parra Toro","userId":"08257295951347696938"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Punto de entrada para crear los RDD\n","sc = spark.sparkContext\n","\n","# Crea un RDD paralelizado con 3 particiones\n","rdd = sc.parallelize([1,2,3,4,5], 3)"],"metadata":{"id":"1End79LSnchJ","executionInfo":{"status":"ok","timestamp":1717622580790,"user_tz":300,"elapsed":532,"user":{"displayName":"Jonatan Alexander Parra Toro","userId":"08257295951347696938"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# Número de particiones\n","rdd.getNumPartitions()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XEObUtNbTJVG","executionInfo":{"status":"ok","timestamp":1717622865744,"user_tz":300,"elapsed":197,"user":{"displayName":"Jonatan Alexander Parra Toro","userId":"08257295951347696938"}},"outputId":"1479c0f2-9b59-41e7-c136-a38e36f5c282"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["# Aumentar número de particiones\n","rdd7 = rdd.repartition(7)\n","rdd7.getNumPartitions()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aFh_pnZETLWl","executionInfo":{"status":"ok","timestamp":1717622868315,"user_tz":300,"elapsed":536,"user":{"displayName":"Jonatan Alexander Parra Toro","userId":"08257295951347696938"}},"outputId":"f22e0ce9-de5e-4ac5-d8da-afd74732667c"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["7"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["\n","\n","\n"],"metadata":{"id":"7rvoy3scJGtW"},"execution_count":null,"outputs":[]}]}